{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b136c98e",
   "metadata": {
    "papermill": {
     "duration": 0.012625,
     "end_time": "2025-02-23T06:44:48.648114",
     "exception": false,
     "start_time": "2025-02-23T06:44:48.635489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Fine-tunning ChatKokkos Example using Standalone Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf2b237",
   "metadata": {
    "papermill": {
     "duration": 0.010674,
     "end_time": "2025-02-23T06:44:48.670524",
     "exception": false,
     "start_time": "2025-02-23T06:44:48.659850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "These are the steps taken to fine-tune ChatKokkos. This is based on the steps developed by Pedro at [Fine-Tuning CodeLLama for Kokkos\n",
    "](https://docs.google.com/document/d/1u_r9PKUYYV_n5vte4oHDeZiPjUa_hnCS-pqdoB8YmF4/edit?tab=t.0) and on the [Hugging Face PEFT Adaptor Training Guide](https://huggingface.co/docs/transformers/en/peft)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5069c934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:44:48.688010Z",
     "iopub.status.busy": "2025-02-23T06:44:48.687678Z",
     "iopub.status.idle": "2025-02-23T06:44:50.170534Z",
     "shell.execute_reply": "2025-02-23T06:44:50.169224Z"
    },
    "papermill": {
     "duration": 1.490655,
     "end_time": "2025-02-23T06:44:50.171953",
     "exception": false,
     "start_time": "2025-02-23T06:44:48.681298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save package state\n",
    "!pip freeze > requirements-lock.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f2bb2d",
   "metadata": {
    "papermill": {
     "duration": 0.005154,
     "end_time": "2025-02-23T06:44:50.182887",
     "exception": false,
     "start_time": "2025-02-23T06:44:50.177733",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dbcdbe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:44:50.194571Z",
     "iopub.status.busy": "2025-02-23T06:44:50.194225Z",
     "iopub.status.idle": "2025-02-23T06:45:01.517774Z",
     "shell.execute_reply": "2025-02-23T06:45:01.516993Z"
    },
    "papermill": {
     "duration": 11.331247,
     "end_time": "2025-02-23T06:45:01.519064",
     "exception": false,
     "start_time": "2025-02-23T06:44:50.187817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, DataCollatorForSeq2Seq, Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d758a0",
   "metadata": {
    "papermill": {
     "duration": 0.01077,
     "end_time": "2025-02-23T06:45:01.541365",
     "exception": false,
     "start_time": "2025-02-23T06:45:01.530595",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d76c2779",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:45:01.564810Z",
     "iopub.status.busy": "2025-02-23T06:45:01.564082Z",
     "iopub.status.idle": "2025-02-23T06:45:01.898581Z",
     "shell.execute_reply": "2025-02-23T06:45:01.897128Z"
    },
    "papermill": {
     "duration": 0.348319,
     "end_time": "2025-02-23T06:45:01.900689",
     "exception": false,
     "start_time": "2025-02-23T06:45:01.552370",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = \"/home/7ry/Data/ellora/ChatKokkos-data/kokkos_dataset_before_reinforcement.json\"\n",
    "\n",
    "train_dataset = load_dataset(\"json\", data_files=data_files, split=\"train\")\n",
    "eval_dataset = load_dataset(\"json\", data_files=data_files, split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d069fd",
   "metadata": {
    "papermill": {
     "duration": 0.005007,
     "end_time": "2025-02-23T06:45:01.917461",
     "exception": false,
     "start_time": "2025-02-23T06:45:01.912454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09ec81a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:45:01.929983Z",
     "iopub.status.busy": "2025-02-23T06:45:01.929580Z",
     "iopub.status.idle": "2025-02-23T06:45:06.186006Z",
     "shell.execute_reply": "2025-02-23T06:45:06.185087Z"
    },
    "papermill": {
     "duration": 4.265624,
     "end_time": "2025-02-23T06:45:06.187943",
     "exception": false,
     "start_time": "2025-02-23T06:45:01.922319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a5fa6e6a8b405082c3d1985012d64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load model directly\n",
    "\n",
    "# base_model_path = \"meta-llama/CodeLlama-7b-hf\"\n",
    "# base_model_path = \"codellama/CodeLlama-7b-hf\"\n",
    "# base_model_path = \"/home/7ry/Data/ellora/models/meta-llama/CodeLlama-7b-hf\"\n",
    "base_model_path = \"/auto/projects/ChatHPC/models/cache/meta-llama/CodeLlama-7b-hf\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    load_in_8bit=False,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    "    # device_map={'':torch.cuda.current_device()}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d35c67",
   "metadata": {
    "papermill": {
     "duration": 0.010804,
     "end_time": "2025-02-23T06:45:06.211820",
     "exception": false,
     "start_time": "2025-02-23T06:45:06.201016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73f50d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:45:06.235722Z",
     "iopub.status.busy": "2025-02-23T06:45:06.235285Z",
     "iopub.status.idle": "2025-02-23T06:45:23.544122Z",
     "shell.execute_reply": "2025-02-23T06:45:23.542826Z"
    },
    "papermill": {
     "duration": 17.322643,
     "end_time": "2025-02-23T06:45:23.545679",
     "exception": false,
     "start_time": "2025-02-23T06:45:06.223036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
      "\n",
      "You must output the answer the question.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "Which kind of Kokkos views are?\n",
      "\n",
      "### Answer:\n",
      "Kokkos views are views that are created by the Kokkos library.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "What is the difference between a Kokkos view and a C++ array?\n",
      "\n",
      "### Answer:\n",
      "A Kokkos view is a C++ array that is managed by the Kokkos library.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "What is the difference between a Kokkos view and a C++ vector?\n",
      "\n",
      "### Answer:\n",
      "A Kokkos view is a C++ vector that is managed by the Kokkos library.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "What is the difference between a Kokkos view and a C++ array?\n",
      "\n",
      "### Answer:\n",
      "A Kokkos view is a C++ array that is managed by the Kokkos library.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "What is the difference between a Kokkos view and a C++ vector?\n",
      "\n",
      "### Answer:\n",
      "A Kokkos view is a C++ vector that is managed by the Kokkos library.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "What is the difference between a Kokkos view and a C++ array?\n",
      "\n",
      "### Answer:\n",
      "A Kokkos view is a C++ array that is managed by the Kokkos library.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "What is the difference between a Kokkos view and a C++ vector?\n",
      "\n",
      "### Answer:\n",
      "A Kokkos view is a C++ vector that is managed by the Kokkos library.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "What is the difference between a Kokkos view and a C++ array?\n",
      "\n",
      "### Answer:\n",
      "A Kokkos view is a C++ array that is managed by the Kokkos library.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "What is the difference between a Kokkos view and a C++ vector?\n",
      "\n",
      "### Answer:\n",
      "A Kokkos view is a C++ vector that is managed by the Kokkos library.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "What is the difference between a Kokkos view and a C++ array?\n",
      "\n",
      "### Answer:\n",
      "A Kokkos view is a C++ array that is managed by the Kokkos library.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "What is the difference between a Kokkos view and a C++ vector?\n",
      "\n",
      "### Answer:\n",
      "A Kokkos view is a C++ vector that is managed by the Kokkos library.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
    "\n",
    "You must output the answer the question.\n",
    "\n",
    "### Context:\n",
    "Introduction to Kokkos programming model\n",
    "\n",
    "### Question:\n",
    "Which kind of Kokkos views are?\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model.generate(**model_input, max_new_tokens=700)[0]\n",
    "    stop = tokenizer.eos_token_id\n",
    "    if stop in output:\n",
    "        print(\"stop found\")\n",
    "    print(tokenizer.decode(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75e7f7dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:45:23.571419Z",
     "iopub.status.busy": "2025-02-23T06:45:23.570989Z",
     "iopub.status.idle": "2025-02-23T06:45:25.959711Z",
     "shell.execute_reply": "2025-02-23T06:45:25.958457Z"
    },
    "papermill": {
     "duration": 2.403064,
     "end_time": "2025-02-23T06:45:25.961337",
     "exception": false,
     "start_time": "2025-02-23T06:45:23.558273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
      "\n",
      "You must output the answer the question.\n",
      "\n",
      "### Context:\n",
      "Kokkos installation\n",
      "\n",
      "### Question:\n",
      "Which compilers can I use to compile Kokkos codes?\n",
      "\n",
      "### Answer:\n",
      "Kokkos can be compiled with the following compilers:\n",
      "\n",
      "* Intel C++ Compiler\n",
      "* GNU C++ Compiler\n",
      "* Clang C++ Compiler\n",
      "\n",
      "### Context:\n",
      "Kokkos installation\n",
      "\n",
      "### Question:\n",
      "Which compilers can I use to compile Kokkos codes?\n",
      "\n",
      "### Answer:\n",
      "Kokkos can be compiled with the following compilers:\n",
      "\n",
      "* Intel C++ Compiler\n",
      "*\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
    "\n",
    "You must output the answer the question.\n",
    "\n",
    "### Context:\n",
    "Kokkos installation\n",
    "\n",
    "### Question:\n",
    "Which compilers can I use to compile Kokkos codes?\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "# {'question': 'Name the comptroller for office of prohibition', 'context': 'CREATE TABLE table_22607062_1 (comptroller VARCHAR, ticket___office VARCHAR)', 'answer': 'SELECT comptroller FROM table_22607062_1 WHERE ticket___office = \"Prohibition\"'}\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09a57bf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:45:25.987272Z",
     "iopub.status.busy": "2025-02-23T06:45:25.987070Z",
     "iopub.status.idle": "2025-02-23T06:45:35.480030Z",
     "shell.execute_reply": "2025-02-23T06:45:35.478769Z"
    },
    "papermill": {
     "duration": 9.507398,
     "end_time": "2025-02-23T06:45:35.481597",
     "exception": false,
     "start_time": "2025-02-23T06:45:25.974199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
      "\n",
      "You must output the answer the question.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "Can you give me an example of Kokkos parallel_reduce?\n",
      "\n",
      "### Answer:\n",
      "\n",
      "```\n",
      "#include <Kokkos_Core.hpp>\n",
      "#include <iostream>\n",
      "\n",
      "int main() {\n",
      "  Kokkos::initialize();\n",
      "  {\n",
      "    Kokkos::View<int*, Kokkos::DefaultHostExecutionSpace> a(\"a\", 10);\n",
      "    Kokkos::parallel_for(10, KOKKOS_LAMBDA(int i) { a(i) = i; });\n",
      "    Kokkos::parallel_reduce(10, 0, KOKKOS_LAMBDA(int i, int& sum) { sum += a(i); }, sum);\n",
      "    std::cout << \"sum = \" << sum << std::endl;\n",
      "  }\n",
      "  Kokkos::finalize();\n",
      "}\n",
      "```\n",
      "\n",
      "### Hints:\n",
      "\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can use the Kokkos documentation to find the answer.\n",
      "* You can\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
    "\n",
    "You must output the answer the question.\n",
    "\n",
    "### Context:\n",
    "Introduction to Kokkos programming model\n",
    "\n",
    "### Question:\n",
    "Can you give me an example of Kokkos parallel_reduce?\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=400)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bca9df",
   "metadata": {
    "papermill": {
     "duration": 0.011683,
     "end_time": "2025-02-23T06:45:35.505769",
     "exception": false,
     "start_time": "2025-02-23T06:45:35.494086",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87358584",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:45:35.517487Z",
     "iopub.status.busy": "2025-02-23T06:45:35.517285Z",
     "iopub.status.idle": "2025-02-23T06:45:35.640998Z",
     "shell.execute_reply": "2025-02-23T06:45:35.640010Z"
    },
    "papermill": {
     "duration": 0.131375,
     "end_time": "2025-02-23T06:45:35.642409",
     "exception": false,
     "start_time": "2025-02-23T06:45:35.511034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4517d8cb04f4467da40c52031a3417a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd258e4e6734775a8ad0e544bdd7df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "{'question': 'What is Kokkos?', 'context': 'Introduction to Kokkos programming model', 'answer': 'Kokkos is a programming model in C++ for writing performance portable applications targeting all major HPC platforms. For that purpose it provides abstractions for both parallel execution of code and data management. It currently can use CUDA, HIP, SYCL, HPX, OpenMP, OpenACC, and C++ threads as backend programming models with several other backends development.', 'input_ids': [1, 887, 526, 263, 13988, 365, 26369, 1904, 363, 476, 554, 29895, 359, 2000, 678, 271, 29968, 554, 29895, 359, 2825, 491, 6323, 25103, 29889, 3575, 4982, 338, 304, 1234, 5155, 1048, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 887, 526, 2183, 263, 1139, 322, 3030, 11211, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 13, 13, 3492, 1818, 1962, 278, 1234, 278, 1139, 29889, 13, 13, 2277, 29937, 15228, 29901, 13, 25898, 304, 476, 554, 29895, 359, 8720, 1904, 13, 13, 2277, 29937, 894, 29901, 13, 5618, 338, 476, 554, 29895, 359, 29973, 13, 13, 2277, 29937, 673, 29901, 13, 29968, 554, 29895, 359, 338, 263, 8720, 1904, 297, 315, 1817, 363, 5007, 4180, 2011, 519, 8324, 3646, 292, 599, 4655, 379, 9026, 21796, 29889, 1152, 393, 6437, 372, 8128, 27086, 1953, 363, 1716, 8943, 8225, 310, 775, 322, 848, 10643, 29889, 739, 5279, 508, 671, 315, 29965, 7698, 29892, 379, 5690, 29892, 28962, 6154, 29892, 379, 29925, 29990, 29892, 4673, 3580, 29892, 4673, 2477, 29907, 29892, 322, 315, 1817, 9717, 408, 14998, 8720, 4733, 411, 3196, 916, 1250, 1975, 5849, 29889, 13, 13, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 887, 526, 263, 13988, 365, 26369, 1904, 363, 476, 554, 29895, 359, 2000, 678, 271, 29968, 554, 29895, 359, 2825, 491, 6323, 25103, 29889, 3575, 4982, 338, 304, 1234, 5155, 1048, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 887, 526, 2183, 263, 1139, 322, 3030, 11211, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 13, 13, 3492, 1818, 1962, 278, 1234, 278, 1139, 29889, 13, 13, 2277, 29937, 15228, 29901, 13, 25898, 304, 476, 554, 29895, 359, 8720, 1904, 13, 13, 2277, 29937, 894, 29901, 13, 5618, 338, 476, 554, 29895, 359, 29973, 13, 13, 2277, 29937, 673, 29901, 13, 29968, 554, 29895, 359, 338, 263, 8720, 1904, 297, 315, 1817, 363, 5007, 4180, 2011, 519, 8324, 3646, 292, 599, 4655, 379, 9026, 21796, 29889, 1152, 393, 6437, 372, 8128, 27086, 1953, 363, 1716, 8943, 8225, 310, 775, 322, 848, 10643, 29889, 739, 5279, 508, 671, 315, 29965, 7698, 29892, 379, 5690, 29892, 28962, 6154, 29892, 379, 29925, 29990, 29892, 4673, 3580, 29892, 4673, 2477, 29907, 29892, 322, 315, 1817, 9717, 408, 14998, 8720, 4733, 411, 3196, 916, 1250, 1975, 5849, 29889, 13, 13, 2]}\n",
      "{'question': 'How is the Kokkos programming model?', 'context': 'Introduction to Kokkos programming model', 'answer': 'The programming model Kokkos is characterized by 6 core abstractions: Execution Spaces, Execution Patterns, Execution Policies, Memory Spaces, Memory Layout and Memory Traits. These abstraction concepts allow the formulation of generic algorithms and data structures which can then be mapped to different types of architectures.', 'input_ids': [1, 887, 526, 263, 13988, 365, 26369, 1904, 363, 476, 554, 29895, 359, 2000, 678, 271, 29968, 554, 29895, 359, 2825, 491, 6323, 25103, 29889, 3575, 4982, 338, 304, 1234, 5155, 1048, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 887, 526, 2183, 263, 1139, 322, 3030, 11211, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 13, 13, 3492, 1818, 1962, 278, 1234, 278, 1139, 29889, 13, 13, 2277, 29937, 15228, 29901, 13, 25898, 304, 476, 554, 29895, 359, 8720, 1904, 13, 13, 2277, 29937, 894, 29901, 13, 5328, 338, 278, 476, 554, 29895, 359, 8720, 1904, 29973, 13, 13, 2277, 29937, 673, 29901, 13, 1576, 8720, 1904, 476, 554, 29895, 359, 338, 2931, 1891, 491, 29871, 29953, 7136, 27086, 1953, 29901, 11080, 918, 1706, 3302, 29892, 11080, 918, 25860, 29879, 29892, 11080, 918, 2043, 293, 583, 29892, 18914, 1706, 3302, 29892, 18914, 20259, 322, 18914, 3201, 1169, 29889, 4525, 27086, 428, 22001, 2758, 278, 883, 2785, 310, 10035, 14009, 322, 848, 12286, 607, 508, 769, 367, 20545, 304, 1422, 4072, 310, 6956, 1973, 29889, 13, 13, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 887, 526, 263, 13988, 365, 26369, 1904, 363, 476, 554, 29895, 359, 2000, 678, 271, 29968, 554, 29895, 359, 2825, 491, 6323, 25103, 29889, 3575, 4982, 338, 304, 1234, 5155, 1048, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 887, 526, 2183, 263, 1139, 322, 3030, 11211, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 13, 13, 3492, 1818, 1962, 278, 1234, 278, 1139, 29889, 13, 13, 2277, 29937, 15228, 29901, 13, 25898, 304, 476, 554, 29895, 359, 8720, 1904, 13, 13, 2277, 29937, 894, 29901, 13, 5328, 338, 278, 476, 554, 29895, 359, 8720, 1904, 29973, 13, 13, 2277, 29937, 673, 29901, 13, 1576, 8720, 1904, 476, 554, 29895, 359, 338, 2931, 1891, 491, 29871, 29953, 7136, 27086, 1953, 29901, 11080, 918, 1706, 3302, 29892, 11080, 918, 25860, 29879, 29892, 11080, 918, 2043, 293, 583, 29892, 18914, 1706, 3302, 29892, 18914, 20259, 322, 18914, 3201, 1169, 29889, 4525, 27086, 428, 22001, 2758, 278, 883, 2785, 310, 10035, 14009, 322, 848, 12286, 607, 508, 769, 367, 20545, 304, 1422, 4072, 310, 6956, 1973, 29889, 13, 13, 2]}\n",
      "{'question': 'What is a Kokkos view?', 'context': 'Introduction to Kokkos programming model', 'answer': 'A Kokkos view is an array of zero or more dimensions, where Kokkos chooses array layout at compile time for best overall performance as a function of the computer architecture.', 'input_ids': [1, 887, 526, 263, 13988, 365, 26369, 1904, 363, 476, 554, 29895, 359, 2000, 678, 271, 29968, 554, 29895, 359, 2825, 491, 6323, 25103, 29889, 3575, 4982, 338, 304, 1234, 5155, 1048, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 887, 526, 2183, 263, 1139, 322, 3030, 11211, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 13, 13, 3492, 1818, 1962, 278, 1234, 278, 1139, 29889, 13, 13, 2277, 29937, 15228, 29901, 13, 25898, 304, 476, 554, 29895, 359, 8720, 1904, 13, 13, 2277, 29937, 894, 29901, 13, 5618, 338, 263, 476, 554, 29895, 359, 1776, 29973, 13, 13, 2277, 29937, 673, 29901, 13, 29909, 476, 554, 29895, 359, 1776, 338, 385, 1409, 310, 5225, 470, 901, 13391, 29892, 988, 476, 554, 29895, 359, 3060, 15806, 1409, 5912, 472, 6633, 931, 363, 1900, 12463, 4180, 408, 263, 740, 310, 278, 6601, 11258, 29889, 13, 13, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1, 887, 526, 263, 13988, 365, 26369, 1904, 363, 476, 554, 29895, 359, 2000, 678, 271, 29968, 554, 29895, 359, 2825, 491, 6323, 25103, 29889, 3575, 4982, 338, 304, 1234, 5155, 1048, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 887, 526, 2183, 263, 1139, 322, 3030, 11211, 278, 476, 554, 29895, 359, 8720, 1904, 29889, 13, 13, 3492, 1818, 1962, 278, 1234, 278, 1139, 29889, 13, 13, 2277, 29937, 15228, 29901, 13, 25898, 304, 476, 554, 29895, 359, 8720, 1904, 13, 13, 2277, 29937, 894, 29901, 13, 5618, 338, 263, 476, 554, 29895, 359, 1776, 29973, 13, 13, 2277, 29937, 673, 29901, 13, 29909, 476, 554, 29895, 359, 1776, 338, 385, 1409, 310, 5225, 470, 901, 13391, 29892, 988, 476, 554, 29895, 359, 3060, 15806, 1409, 5912, 472, 6633, 931, 363, 1900, 12463, 4180, 408, 263, 740, 310, 278, 6601, 11258, 29889, 13, 13, 2]}\n"
     ]
    }
   ],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.unk_token\n",
    "\n",
    "\n",
    "def tokenize(prompt):\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    )\n",
    "\n",
    "    # \"self-supervised learning\" means the labels are also the inputs:\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = f\"\"\"You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
    "\n",
    "You must output the answer the question.\n",
    "\n",
    "### Context:\n",
    "{data_point[\"context\"]}\n",
    "\n",
    "### Question:\n",
    "{data_point[\"question\"]}\n",
    "\n",
    "### Answer:\n",
    "{data_point[\"answer\"]}\n",
    "\n",
    "\"\"\"\n",
    "    return tokenize(full_prompt)\n",
    "\n",
    "\n",
    "tokenizer.add_eos_token = True\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
    "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)\n",
    "\n",
    "tokenizer.add_eos_token = False\n",
    "\n",
    "print(len(tokenized_train_dataset))\n",
    "print(tokenized_train_dataset[0])\n",
    "print(tokenized_train_dataset[1])\n",
    "print(tokenized_train_dataset[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb4edc9",
   "metadata": {
    "papermill": {
     "duration": 0.012149,
     "end_time": "2025-02-23T06:45:35.667927",
     "exception": false,
     "start_time": "2025-02-23T06:45:35.655778",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup Lora and training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0098ca38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:45:35.687762Z",
     "iopub.status.busy": "2025-02-23T06:45:35.687345Z",
     "iopub.status.idle": "2025-02-23T06:45:40.366530Z",
     "shell.execute_reply": "2025-02-23T06:45:40.365715Z"
    },
    "papermill": {
     "duration": 4.688154,
     "end_time": "2025-02-23T06:45:40.368400",
     "exception": false,
     "start_time": "2025-02-23T06:45:35.680246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,777,216 || all params: 6,755,323,904 || trainable%: 0.2484\n",
      "multiple gpus detected!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiling the model\n"
     ]
    }
   ],
   "source": [
    "from pytz import timezone\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    r=16,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\n",
    "        \"q_proj\",\n",
    "        \"k_proj\",\n",
    "        \"v_proj\",\n",
    "        \"o_proj\",\n",
    "    ],\n",
    ")\n",
    "model.train()  # put model back into training mode\n",
    "# model = prepare_model_for_int8_training(model)\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, peft_config)\n",
    "# model.add_adapter(peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# self.model = DataParallel(self.model)\n",
    "\n",
    "batch_size = 128\n",
    "per_device_train_batch_size = 32\n",
    "gradient_accumulation_steps = batch_size // per_device_train_batch_size\n",
    "output_dir = \"kokkos-code-llama\"\n",
    "\n",
    "# resume_from_checkpoint = os.path.join(base_model_path, \"pytorch_model-00001-of-00003.bin\")\n",
    "\n",
    "# if resume_from_checkpoint:\n",
    "#     if os.path.exists(resume_from_checkpoint):\n",
    "#         print(f\"Restarting from {resume_from_checkpoint}\")\n",
    "#         adapters_weights = torch.load(resume_from_checkpoint)\n",
    "#         set_peft_model_state_dict(model, adapters_weights)\n",
    "#     else:\n",
    "#         print(f\"Checkpoint {resume_from_checkpoint} not found\")\n",
    "\n",
    "\n",
    "wandb_project = \"ChatHPC Application\"\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    # keeps Trainer from trying its own DataParallelism when more than 1 gpu is available\n",
    "    print(\"multiple gpus detected!\")\n",
    "    model.is_parallelizable = True\n",
    "    model.model_parallel = True\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    warmup_steps=100,\n",
    "    max_steps=400,\n",
    "    # max_steps=20,\n",
    "    learning_rate=3e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    optim=\"adamw_torch\",\n",
    "    eval_strategy=\"steps\",  # if val_set_size > 0 else \"no\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=20,\n",
    "    save_steps=20,\n",
    "    output_dir=output_dir,\n",
    "    # save_total_limit=3,\n",
    "    load_best_model_at_end=False,\n",
    "    # ddp_find_unused_parameters=False if ddp else None,\n",
    "    group_by_length=True,  # group sequences of roughly the same length together to speed up training\n",
    "    report_to=\"wandb\",  # if use_wandb else \"none\",\n",
    "    run_name=f\"codellama-{datetime.now(tz=timezone('EST')).strftime('%Y-%m-%d-%H-%M')}\",  # if use_wandb else None,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True),\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "\n",
    "# old_state_dict = model.state_dit\n",
    "# model.state_dict = (lambda self, *_, **__: get_peft_model_state_dict(self, old_state_dict())).__get__(\n",
    "#     model, type(model)\n",
    "# )\n",
    "\n",
    "if torch.__version__ >= \"2\" and sys.platform != \"win32\":\n",
    "    print(\"compiling the model\")\n",
    "    model = torch.compile(model)\n",
    "\n",
    "# model.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85599f19",
   "metadata": {
    "papermill": {
     "duration": 0.012522,
     "end_time": "2025-02-23T06:45:40.394154",
     "exception": false,
     "start_time": "2025-02-23T06:45:40.381632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37bd3048",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T06:45:40.419875Z",
     "iopub.status.busy": "2025-02-23T06:45:40.419434Z",
     "iopub.status.idle": "2025-02-23T07:05:16.411970Z",
     "shell.execute_reply": "2025-02-23T07:05:16.411073Z"
    },
    "papermill": {
     "duration": 1176.007378,
     "end_time": "2025-02-23T07:05:16.413746",
     "exception": false,
     "start_time": "2025-02-23T06:45:40.406368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mgeekdude\u001b[0m (\u001b[33mgeekdude-oak-ridge-national-laboratory\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/7ry/Data/ellora/ChatHPC-app-new-data/examples/wandb/run-20250223_014541-hnfgg9lu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcodellama-2025-02-23-01-45\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/geekdude-oak-ridge-national-laboratory/ChatHPC%20Application\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/geekdude-oak-ridge-national-laboratory/ChatHPC%20Application/runs/hnfgg9lu\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 19:30, Epoch 400/400]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>3.229400</td>\n",
       "      <td>1.513318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.977200</td>\n",
       "      <td>0.731332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.893800</td>\n",
       "      <td>0.387988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.493300</td>\n",
       "      <td>0.182084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.140300</td>\n",
       "      <td>0.045444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.020325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.019123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.019064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.018961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.018957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.018919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>0.018850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.018882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.018836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.018827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>320</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.018809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.018885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>360</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.018745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>380</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.018783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.018833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.4063806514441967, metrics={'train_runtime': 1175.7523, 'train_samples_per_second': 43.547, 'train_steps_per_second': 0.34, 'total_flos': 3.744308096139264e+17, 'train_loss': 0.4063806514441967, 'epoch': 400.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c29db2c",
   "metadata": {
    "papermill": {
     "duration": 0.009167,
     "end_time": "2025-02-23T07:05:16.442814",
     "exception": false,
     "start_time": "2025-02-23T07:05:16.433647",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08ead588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T07:05:16.459696Z",
     "iopub.status.busy": "2025-02-23T07:05:16.459157Z",
     "iopub.status.idle": "2025-02-23T07:05:16.836016Z",
     "shell.execute_reply": "2025-02-23T07:05:16.835078Z"
    },
    "papermill": {
     "duration": 0.387161,
     "end_time": "2025-02-23T07:05:16.837761",
     "exception": false,
     "start_time": "2025-02-23T07:05:16.450600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_dir = \"./peft_adapter\"\n",
    "save_dir_tokenize = \"./tokenizer\"\n",
    "save_dir_embedding_layers = \"./embedding_layers\"\n",
    "tokenizer.save_pretrained(save_dir_tokenize)\n",
    "trainer.model.save_pretrained(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82c40a",
   "metadata": {
    "papermill": {
     "duration": 0.010067,
     "end_time": "2025-02-23T07:05:16.866176",
     "exception": false,
     "start_time": "2025-02-23T07:05:16.856109",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load back trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0212b8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T07:05:16.884121Z",
     "iopub.status.busy": "2025-02-23T07:05:16.883298Z",
     "iopub.status.idle": "2025-02-23T07:07:08.661659Z",
     "shell.execute_reply": "2025-02-23T07:07:08.660939Z"
    },
    "papermill": {
     "duration": 111.803917,
     "end_time": "2025-02-23T07:07:08.678534",
     "exception": false,
     "start_time": "2025-02-23T07:05:16.874617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f15a86d168c40368e21cfaa2ecd8fa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('merged_adapters/tokenizer_config.json',\n",
       " 'merged_adapters/special_tokens_map.json',\n",
       " 'merged_adapters/tokenizer.model',\n",
       " 'merged_adapters/added_tokens.json',\n",
       " 'merged_adapters/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load model directly\n",
    "import torch\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# base_model_path = \"meta-llama/CodeLlama-7b-hf\"\n",
    "# base_model_path = \"codellama/CodeLlama-7b-hf\"\n",
    "# base_model_path = \"/home/7ry/Data/ellora/models/meta-llama/CodeLlama-7b-hf\"\n",
    "base_model_path = \"/auto/projects/ChatHPC/models/cache/meta-llama/CodeLlama-7b-hf\"\n",
    "save_dir = \"./peft_adapter\"\n",
    "save_dir_tokenize = \"./tokenizer\"\n",
    "save_dir_embedding_layers = \"./embedding_layers\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_path)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_path,\n",
    "    load_in_8bit=False,\n",
    "    torch_dtype=torch.float,\n",
    "    device_map=\"auto\",\n",
    "    # use_safe_serialization=False\n",
    "    # device_map={'':torch.cuda.current_device()}\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(model, save_dir)\n",
    "\n",
    "model = model.merge_and_unload()\n",
    "model.save_pretrained(\"merged_adapters\")\n",
    "tokenizer.save_pretrained(\"merged_adapters\")\n",
    "\n",
    "# model.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1deb0",
   "metadata": {
    "papermill": {
     "duration": 0.006847,
     "end_time": "2025-02-23T07:07:08.692691",
     "exception": false,
     "start_time": "2025-02-23T07:07:08.685844",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74ddbc6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T07:07:08.707199Z",
     "iopub.status.busy": "2025-02-23T07:07:08.706995Z",
     "iopub.status.idle": "2025-02-23T07:07:09.237785Z",
     "shell.execute_reply": "2025-02-23T07:07:09.237221Z"
    },
    "papermill": {
     "duration": 0.539521,
     "end_time": "2025-02-23T07:07:09.238902",
     "exception": false,
     "start_time": "2025-02-23T07:07:08.699381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
      "\n",
      "You must output the answer the question.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "Which kind of Kokkos views are?\n",
      "\n",
      "### Answer:\n",
      "There are two different layouts; LayoutLeft and LayoutRight.\n",
      "\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
    "\n",
    "You must output the answer the question.\n",
    "\n",
    "### Context:\n",
    "Introduction to Kokkos programming model\n",
    "\n",
    "### Question:\n",
    "Which kind of Kokkos views are?\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3781f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T07:07:09.261803Z",
     "iopub.status.busy": "2025-02-23T07:07:09.261641Z",
     "iopub.status.idle": "2025-02-23T07:07:15.116677Z",
     "shell.execute_reply": "2025-02-23T07:07:15.116082Z"
    },
    "papermill": {
     "duration": 5.86374,
     "end_time": "2025-02-23T07:07:15.117980",
     "exception": false,
     "start_time": "2025-02-23T07:07:09.254240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
      "\n",
      "You must output the answer the question.\n",
      "\n",
      "### Context:\n",
      "Kokkos installation\n",
      "\n",
      "### Question:\n",
      "Which compilers can I use to compile Kokkos codes?\n",
      "\n",
      "### Answer:\n",
      "```txt\n",
      "Minimum Compiler Versions:\n",
      " GCC: 5.3.0\n",
      " Clang: 4.0.0  (CPU)\n",
      " Clang: 10.0.0 (as CUDA compiler)\n",
      " Intel: 17.0.1\n",
      " NVCC: 9.2.88\n",
      " NVC++: 21.5\n",
      " ROCM: 4.5\n",
      " MSVC: 19.29\n",
      " IBM XL: 16.1.1\n",
      " Fujitsu: 4.5.0\n",
      " ARM/Clang 20.1\n",
      "\n",
      "Primary Tested Compilers:\n",
      " GCC: 5.3.0, 6.1.0, 7.3.0, 8.3, 9.2, 10.0\n",
      " NVCC: 9.2.88, 10.1, 11.0\n",
      " Clang: 8.0.0, 9.0.0, 10.0.0, 12.0.0\n",
      " Intel 17.4, 18.1, 19.5\n",
      " MSVC: 19.29\n",
      " ARM/Clang: 20.1\n",
      " IBM XL: 16.1.1\n",
      " ROCM: 4.5.0\n",
      "```\n",
      "\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
    "\n",
    "You must output the answer the question.\n",
    "\n",
    "### Context:\n",
    "Kokkos installation\n",
    "\n",
    "### Question:\n",
    "Which compilers can I use to compile Kokkos codes?\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "# {'question': 'Name the comptroller for office of prohibition', 'context': 'CREATE TABLE table_22607062_1 (comptroller VARCHAR, ticket___office VARCHAR)', 'answer': 'SELECT comptroller FROM table_22607062_1 WHERE ticket___office = \"Prohibition\"'}\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=500)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1523ec70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T07:07:15.142566Z",
     "iopub.status.busy": "2025-02-23T07:07:15.141962Z",
     "iopub.status.idle": "2025-02-23T07:07:19.497158Z",
     "shell.execute_reply": "2025-02-23T07:07:19.496567Z"
    },
    "papermill": {
     "duration": 4.364464,
     "end_time": "2025-02-23T07:07:19.498571",
     "exception": false,
     "start_time": "2025-02-23T07:07:15.134107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
      "\n",
      "You must output the answer the question.\n",
      "\n",
      "### Context:\n",
      "Introduction to Kokkos programming model\n",
      "\n",
      "### Question:\n",
      "Can you give me an example of Kokkos parallel_reduce?\n",
      "\n",
      "### Answer:\n",
      "```cpp\n",
      "#include <Kokkos_Core.hpp>\n",
      "int main( int argc, char* argv[] ) {\n",
      "  int M = 10;\n",
      "  Kokkos::initialize( argc, argv ); {\n",
      "    auto X  = static_cast<float*>(Kokkos::kokkos_malloc<>(M * sizeof(float)));\n",
      "    Kokkos::parallel_for( M, KOKKOS_LAMBDA ( int m ) {\n",
      "      X(m) = 2.0;\n",
      "    });\n",
      "    Kokkos::parallel_reduce( M, KOKKOS_LAMBDA ( int m, float &update ) {\n",
      "      update += X[m]; }, Kokkos::Sum<float>(result) );\n",
      "    Kokkos::fence();\n",
      "    Kokkos::kokkos_free<>(X);\n",
      "  }\n",
      "  Kokkos::finalize();\n",
      "  return 0;\n",
      "}\n",
      "```\n",
      "\n",
      "</s>\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"You are a powerful LLM model for Kokkos called ChatKokkos created by ORNL. Your job is to answer questions about the Kokkos programming model. You are given a question and context regarding the Kokkos programming model.\n",
    "\n",
    "You must output the answer the question.\n",
    "\n",
    "### Context:\n",
    "Introduction to Kokkos programming model\n",
    "\n",
    "### Question:\n",
    "Can you give me an example of Kokkos parallel_reduce?\n",
    "\n",
    "### Answer:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=700)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882622f4",
   "metadata": {
    "papermill": {
     "duration": 0.00687,
     "end_time": "2025-02-23T07:07:19.522016",
     "exception": false,
     "start_time": "2025-02-23T07:07:19.515146",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Exit kernel to free up resources when done running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "521de1d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-23T07:07:19.536683Z",
     "iopub.status.busy": "2025-02-23T07:07:19.536337Z",
     "iopub.status.idle": "2025-02-23T07:07:19.540697Z",
     "shell.execute_reply": "2025-02-23T07:07:19.540083Z"
    },
    "papermill": {
     "duration": 0.012455,
     "end_time": "2025-02-23T07:07:19.541277",
     "exception": true,
     "start_time": "2025-02-23T07:07:19.528822",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/7ry/Data/ellora/ChatHPC-app-new-data/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1355.064104,
   "end_time": "2025-02-23T07:07:22.566943",
   "environment_variables": {},
   "exception": true,
   "input_path": "/home/7ry/Data/ellora/ChatHPC-app-new-data/examples/fine-tune-chat-kokkos.ipynb",
   "output_path": "/home/7ry/Data/ellora/ChatHPC-app-new-data/examples/fine-tune-chat-kokkos_output.ipynb",
   "parameters": {},
   "start_time": "2025-02-23T06:44:47.502839",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01024731632141ac807ede24f3caf0f0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "055d33f684e84ba7b47e84375669d683": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "06263d4150644585993076701d0bb4c9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "09381567db2146b287f6986b22617302": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "15f56e980d1f4e05b8f543ffdf158f5c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2033aad00ae04eadb77d03f370d2a6ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ff2ae124679949c59855294a7d78a36d",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_06263d4150644585993076701d0bb4c9",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
      }
     },
     "2a8d26ffd90c466aafdd5ec95be0592d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "2ad892a68740487e96cadb7dce3cc0b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2be33387fb934d1a92972fc6e96e8537": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2e8ab10285f2472eb64d07948ba64a57": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f42dbf4368543a6806d8c4bd806d0a2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3568535487c7412cb8bc3ba52472482f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ea58436dbc49468b81283e0e393af0c2",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6b56cdddfaca4bf2b1160553b567668e",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "3a6ad62cbac4449d9dfeb6f09a968ec9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3eb42c3a7d8f41c6b7789eee13d11b7f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3a6ad62cbac4449d9dfeb6f09a968ec9",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_dfb0589644824751ad2650d241c3dea0",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá64/64‚Äá[00:00&lt;00:00,‚Äá1692.05‚Äáexamples/s]"
      }
     },
     "3f719aee71024969acf7651ae9e4d65d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4517d8cb04f4467da40c52031a3417a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c6996b1087634b5590e442616d1cb696",
        "IPY_MODEL_6b045352fc6242f7ad409bcddaef2131",
        "IPY_MODEL_5c41d1720dae492da62b0646c341115e"
       ],
       "layout": "IPY_MODEL_5500a9e3a0264beeaead4e3e024c1cba",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4b64f71ae4304fbaa04987fa3ca51ccb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "51a11b5ae8ea486bb7405011c5f010ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2f42dbf4368543a6806d8c4bd806d0a2",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_a2c2735a2a03448282a9338ba79247aa",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
      }
     },
     "5500a9e3a0264beeaead4e3e024c1cba": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "567238d9d2eb4fd4bd2355d5d5968b0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5c41d1720dae492da62b0646c341115e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_15f56e980d1f4e05b8f543ffdf158f5c",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_09381567db2146b287f6986b22617302",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá64/64‚Äá[00:00&lt;00:00,‚Äá1654.16‚Äáexamples/s]"
      }
     },
     "5cd258e4e6734775a8ad0e544bdd7df5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f7e4b10fc35d43c0ad923309a6b7aac5",
        "IPY_MODEL_86bef4d9203949dcafee017aec0234b4",
        "IPY_MODEL_3eb42c3a7d8f41c6b7789eee13d11b7f"
       ],
       "layout": "IPY_MODEL_8b6b331f7b914349b6257fe2e29e26f5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "64647892af20468dac6ce3c674537f9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2be33387fb934d1a92972fc6e96e8537",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9534d87c1eed4c159c378743af0da979",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "6b045352fc6242f7ad409bcddaef2131": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4b64f71ae4304fbaa04987fa3ca51ccb",
       "max": 64.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3f719aee71024969acf7651ae9e4d65d",
       "tabbable": null,
       "tooltip": null,
       "value": 64.0
      }
     },
     "6b56cdddfaca4bf2b1160553b567668e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "6f15a86d168c40368e21cfaa2ecd8fa6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2033aad00ae04eadb77d03f370d2a6ba",
        "IPY_MODEL_3568535487c7412cb8bc3ba52472482f",
        "IPY_MODEL_8ab7f2ce111a4c5a9b488e5b76fb0973"
       ],
       "layout": "IPY_MODEL_9fe6a40f635f48c7a3a56ca199298322",
       "tabbable": null,
       "tooltip": null
      }
     },
     "86bef4d9203949dcafee017aec0234b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_01024731632141ac807ede24f3caf0f0",
       "max": 64.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_2a8d26ffd90c466aafdd5ec95be0592d",
       "tabbable": null,
       "tooltip": null,
       "value": 64.0
      }
     },
     "8ab7f2ce111a4c5a9b488e5b76fb0973": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8f5c4fefb52c4b6397d67b2a01c50fec",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_9a561de27fb24cd1a80df3adac5c75af",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá2/2‚Äá[00:05&lt;00:00,‚Äá‚Äá2.53s/it]"
      }
     },
     "8b6b331f7b914349b6257fe2e29e26f5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f5c4fefb52c4b6397d67b2a01c50fec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9534d87c1eed4c159c378743af0da979": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9a561de27fb24cd1a80df3adac5c75af": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9d54fbf0709843ef81ba4d59adf86fb5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9fe6a40f635f48c7a3a56ca199298322": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2c2735a2a03448282a9338ba79247aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b5a5fa6e6a8b405082c3d1985012d64d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_51a11b5ae8ea486bb7405011c5f010ad",
        "IPY_MODEL_64647892af20468dac6ce3c674537f9c",
        "IPY_MODEL_c1707e2437364677b1671844f0dac4de"
       ],
       "layout": "IPY_MODEL_2ad892a68740487e96cadb7dce3cc0b7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c1707e2437364677b1671844f0dac4de": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2e8ab10285f2472eb64d07948ba64a57",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_f330cb7b80d54591bd2c54d2e291eb60",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá2/2‚Äá[00:03&lt;00:00,‚Äá‚Äá1.56s/it]"
      }
     },
     "c6996b1087634b5590e442616d1cb696": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_055d33f684e84ba7b47e84375669d683",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_567238d9d2eb4fd4bd2355d5d5968b0e",
       "tabbable": null,
       "tooltip": null,
       "value": "Map:‚Äá100%"
      }
     },
     "d26c151b55584310b5eec69eef57fbee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfb0589644824751ad2650d241c3dea0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ea58436dbc49468b81283e0e393af0c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f330cb7b80d54591bd2c54d2e291eb60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f7e4b10fc35d43c0ad923309a6b7aac5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d26c151b55584310b5eec69eef57fbee",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_9d54fbf0709843ef81ba4d59adf86fb5",
       "tabbable": null,
       "tooltip": null,
       "value": "Map:‚Äá100%"
      }
     },
     "ff2ae124679949c59855294a7d78a36d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}